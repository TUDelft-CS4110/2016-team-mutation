<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="en"><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../.resources/report.css" type="text/css"/><link rel="shortcut icon" href="../.resources/report.gif" type="image/gif"/><title>RobotstxtServer.java</title><link rel="stylesheet" href="../.resources/prettify.css" type="text/css"/><script type="text/javascript" src="../.resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../.sessions.html" class="el_session">Sessions</a></span><a href="../index.html" class="el_report">crawler4j</a> &gt; <a href="index.source.html" class="el_package">edu.uci.ics.crawler4j.robotstxt</a> &gt; <span class="el_source">RobotstxtServer.java</span></div><h1>RobotstxtServer.java</h1><pre class="source lang-java linenums">/**
 * Licensed to the Apache Software Foundation (ASF) under one or more
 * contributor license agreements.  See the NOTICE file distributed with
 * this work for additional information regarding copyright ownership.
 * The ASF licenses this file to You under the Apache License, Version 2.0
 * (the &quot;License&quot;); you may not use this file except in compliance with
 * the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package edu.uci.ics.crawler4j.robotstxt;

import java.net.MalformedURLException;
import java.net.SocketException;
import java.net.SocketTimeoutException;
import java.net.URL;
import java.net.UnknownHostException;
import java.util.HashMap;
import java.util.Map;

import org.apache.http.HttpStatus;
import org.apache.http.NoHttpResponseException;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import edu.uci.ics.crawler4j.crawler.Page;
import edu.uci.ics.crawler4j.crawler.exceptions.PageBiggerThanMaxSizeException;
import edu.uci.ics.crawler4j.fetcher.PageFetchResult;
import edu.uci.ics.crawler4j.fetcher.PageFetcher;
import edu.uci.ics.crawler4j.url.WebURL;
import edu.uci.ics.crawler4j.util.Util;

/**
 * @author Yasser Ganjisaffar
 */
public class RobotstxtServer {

<span class="nc" id="L45">  private static final Logger logger = LoggerFactory.getLogger(RobotstxtServer.class);</span>

  protected RobotstxtConfig config;

<span class="nc" id="L49">  protected final Map&lt;String, HostDirectives&gt; host2directivesCache = new HashMap&lt;&gt;();</span>

  protected PageFetcher pageFetcher;

<span class="nc" id="L53">  public RobotstxtServer(RobotstxtConfig config, PageFetcher pageFetcher) {</span>
<span class="nc" id="L54">    this.config = config;</span>
<span class="nc" id="L55">    this.pageFetcher = pageFetcher;</span>
<span class="nc" id="L56">  }</span>

  private static String getHost(URL url) {
<span class="nc" id="L59">    return url.getHost().toLowerCase();</span>
  }

  /** Please note that in the case of a bad URL, TRUE will be returned */
  public boolean allows(WebURL webURL) {
<span class="nc bnc" id="L64" title="All 2 branches missed.">    if (config.isEnabled()) {</span>
      try {
<span class="nc" id="L66">        URL url = new URL(webURL.getURL());</span>
<span class="nc" id="L67">        String host = getHost(url);</span>
<span class="nc" id="L68">        String path = url.getPath();</span>

<span class="nc" id="L70">        HostDirectives directives = host2directivesCache.get(host);</span>

<span class="nc bnc" id="L72" title="All 4 branches missed.">        if ((directives != null) &amp;&amp; directives.needsRefetch()) {</span>
<span class="nc" id="L73">          synchronized (host2directivesCache) {</span>
<span class="nc" id="L74">            host2directivesCache.remove(host);</span>
<span class="nc" id="L75">            directives = null;</span>
<span class="nc" id="L76">          }</span>
        }

<span class="nc bnc" id="L79" title="All 2 branches missed.">        if (directives == null) {</span>
<span class="nc" id="L80">          directives = fetchDirectives(url);</span>
        }

<span class="nc" id="L83">        return directives.allows(path);</span>
<span class="nc" id="L84">      } catch (MalformedURLException e) {</span>
<span class="nc" id="L85">        logger.error(&quot;Bad URL in Robots.txt: &quot; + webURL.getURL(), e);</span>
      }
    }

<span class="nc" id="L89">    return true;</span>
  }

  private HostDirectives fetchDirectives(URL url) {
<span class="nc" id="L93">    WebURL robotsTxtUrl = new WebURL();</span>
<span class="nc" id="L94">    String host = getHost(url);</span>
<span class="nc bnc" id="L95" title="All 4 branches missed.">    String port = ((url.getPort() == url.getDefaultPort()) || (url.getPort() == -1)) ? &quot;&quot; : (&quot;:&quot; + url.getPort());</span>
<span class="nc" id="L96">    robotsTxtUrl.setURL(&quot;http://&quot; + host + port + &quot;/robots.txt&quot;);</span>
<span class="nc" id="L97">    HostDirectives directives = null;</span>
<span class="nc" id="L98">    PageFetchResult fetchResult = null;</span>
    try {
<span class="nc" id="L100">      fetchResult = pageFetcher.fetchPage(robotsTxtUrl);</span>
<span class="nc bnc" id="L101" title="All 2 branches missed.">      if (fetchResult.getStatusCode() == HttpStatus.SC_OK) {</span>
<span class="nc" id="L102">        Page page = new Page(robotsTxtUrl);</span>
<span class="nc" id="L103">        fetchResult.fetchContent(page);</span>
<span class="nc bnc" id="L104" title="All 2 branches missed.">        if (Util.hasPlainTextContent(page.getContentType())) {</span>
          String content;
<span class="nc bnc" id="L106" title="All 2 branches missed.">          if (page.getContentCharset() == null) {</span>
<span class="nc" id="L107">            content = new String(page.getContentData());</span>
          } else {
<span class="nc" id="L109">            content = new String(page.getContentData(), page.getContentCharset());</span>
          }
<span class="nc" id="L111">          directives = RobotstxtParser.parse(content, config.getUserAgentName());</span>
<span class="nc bnc" id="L112" title="All 2 branches missed.">        } else if (page.getContentType().contains(&quot;html&quot;)) { // TODO This one should be upgraded to remove all html tags</span>
<span class="nc" id="L113">          String content = new String(page.getContentData());</span>
<span class="nc" id="L114">          directives = RobotstxtParser.parse(content, config.getUserAgentName());</span>
<span class="nc" id="L115">        } else {</span>
<span class="nc" id="L116">          logger.warn(&quot;Can't read this robots.txt: {}  as it is not written in plain text, contentType: {}&quot;,</span>
                      robotsTxtUrl.getURL(), page.getContentType());
        }
<span class="nc" id="L119">      } else {</span>
<span class="nc" id="L120">        logger.debug(&quot;Can't read this robots.txt: {}  as it's status code is {}&quot;, robotsTxtUrl.getURL(),</span>
                     fetchResult.getStatusCode());
      }
<span class="nc" id="L123">    } catch (SocketException | UnknownHostException | SocketTimeoutException | NoHttpResponseException se) {</span>
      // No logging here, as it just means that robots.txt doesn't exist on this server which is perfectly ok
<span class="nc" id="L125">    } catch (PageBiggerThanMaxSizeException pbtms) {</span>
<span class="nc" id="L126">      logger.error(&quot;Error occurred while fetching (robots) url: {}, {}&quot;, robotsTxtUrl.getURL(), pbtms.getMessage());</span>
<span class="nc" id="L127">    } catch (Exception e) {</span>
<span class="nc" id="L128">      logger.error(&quot;Error occurred while fetching (robots) url: &quot; + robotsTxtUrl.getURL(), e);</span>
    } finally {
<span class="nc bnc" id="L130" title="All 10 branches missed.">      if (fetchResult != null) {</span>
<span class="nc" id="L131">        fetchResult.discardContentIfNotConsumed();</span>
      }
    }

<span class="nc bnc" id="L135" title="All 2 branches missed.">    if (directives == null) {</span>
      // We still need to have this object to keep track of the time we fetched it
<span class="nc" id="L137">      directives = new HostDirectives();</span>
    }
<span class="nc" id="L139">    synchronized (host2directivesCache) {</span>
<span class="nc bnc" id="L140" title="All 2 branches missed.">      if (host2directivesCache.size() == config.getCacheSize()) {</span>
<span class="nc" id="L141">        String minHost = null;</span>
<span class="nc" id="L142">        long minAccessTime = Long.MAX_VALUE;</span>
<span class="nc bnc" id="L143" title="All 2 branches missed.">        for (Map.Entry&lt;String, HostDirectives&gt; entry : host2directivesCache.entrySet()) {</span>
<span class="nc bnc" id="L144" title="All 2 branches missed.">          if (entry.getValue().getLastAccessTime() &lt; minAccessTime) {</span>
<span class="nc" id="L145">            minAccessTime = entry.getValue().getLastAccessTime();</span>
<span class="nc" id="L146">            minHost = entry.getKey();</span>
          }
<span class="nc" id="L148">        }</span>
<span class="nc" id="L149">        host2directivesCache.remove(minHost);</span>
      }
<span class="nc" id="L151">      host2directivesCache.put(host, directives);</span>
<span class="nc" id="L152">    }</span>
<span class="nc" id="L153">    return directives;</span>
  }
}
</pre><div class="footer"><span class="right">Created with <a href="http://www.eclemma.org/jacoco">JaCoCo</a> 0.7.6.201602180812</span></div></body></html>